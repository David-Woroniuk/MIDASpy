{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MIDASpy demonstration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides a brief demonstration of **MIDASpy**'s core functionalities. We show how to use the package to impute missing values in the [Adult census dataset](https://github.com/MIDASverse/MIDASpy/blob/master/Examples/adult_data.csv) (which is commonly used for benchmarking machine learning tasks).\n",
        "\n",
        "Users of **MIDASpy** must have **TensorFlow** installed as a **pip** package in their Python environment. **MIDASpy** is compatible with both **TensorFlow** 1.X and **TensorFlow** >= 2.2 versions.\n",
        "\n",
        "\n",
        "Once these packages are installed, users can import the dependencies and load the data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import MIDASpy as md\n",
        "\n",
        "data_0 = pd.read_csv('adult_data.csv')\n",
        "data_0.columns.str.strip()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'age', 'workclass', 'fnlwgt', 'education',\n",
              "       'education_num', 'marital_status', 'occupation', 'relationship', 'race',\n",
              "       'sex', 'capital_gain', 'capital_loss', 'hours_per_week',\n",
              "       'native_country', 'class_labels'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the Adult dataset has very little missingness, we randomly set 5,000 observed values as missing in each column:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "np.random.seed(441)\n",
        "\n",
        "def spike_in_generation(data):\n",
        "    spike_in = pd.DataFrame(np.zeros_like(data), columns= data.columns)\n",
        "    for column in data.columns:\n",
        "        subset = np.random.choice(data[column].index[data[column].notnull()], 5000, replace= False)\n",
        "        spike_in.loc[subset, column] = 1\n",
        "    return spike_in\n",
        "\n",
        "spike_in = spike_in_generation(data_0)\n",
        "original_value = data_0.loc[4, 'hours_per_week']\n",
        "data_0[spike_in == 1] = np.nan"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we list categorical variables in a vector and one-hot encode them using **MIDASpy**'s inbuilt preprocessing function `cat_conv`, which returns both the encoded data and a nested list of categorical column names we can pass to the imputation algorithm. To construct the final, pre-processed data we append the one-hot encoded categorical data to the non-cateogrical data, and replace null values with `np.nan` values:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "categorical = ['workclass','marital_status','relationship','race','class_labels','sex','education','occupation','native_country']\n",
        "data_cat, cat_cols_list = md.cat_conv(data_0[categorical])\n",
        "\n",
        "data_0.drop(categorical, axis = 1, inplace = True)\n",
        "constructor_list = [data_0]\n",
        "constructor_list.append(data_cat)\n",
        "data_in = pd.concat(constructor_list, axis=1)\n",
        "\n",
        "na_loc = data_in.isnull()\n",
        "data_in[na_loc] = np.nan"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the results:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "print(data_in.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0   age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
            "0         0.0  39.0   77516.0           13.0        2174.0           0.0   \n",
            "1         1.0  50.0   83311.0           13.0           0.0           0.0   \n",
            "2         2.0  38.0  215646.0            9.0           0.0           0.0   \n",
            "3         3.0  53.0  234721.0            NaN           0.0           0.0   \n",
            "4         4.0  28.0       NaN           13.0           0.0           NaN   \n",
            "\n",
            "   hours_per_week  workclass_Federal-gov  workclass_Local-gov  \\\n",
            "0            40.0                    0.0                  0.0   \n",
            "1            13.0                    0.0                  0.0   \n",
            "2            40.0                    0.0                  0.0   \n",
            "3            40.0                    0.0                  0.0   \n",
            "4             NaN                    0.0                  0.0   \n",
            "\n",
            "   workclass_Never-worked  ...  native_country_Portugal  \\\n",
            "0                     0.0  ...                      0.0   \n",
            "1                     0.0  ...                      0.0   \n",
            "2                     0.0  ...                      0.0   \n",
            "3                     0.0  ...                      0.0   \n",
            "4                     0.0  ...                      0.0   \n",
            "\n",
            "   native_country_Puerto-Rico  native_country_Scotland  native_country_South  \\\n",
            "0                         0.0                      0.0                   0.0   \n",
            "1                         0.0                      0.0                   0.0   \n",
            "2                         0.0                      0.0                   0.0   \n",
            "3                         0.0                      0.0                   0.0   \n",
            "4                         0.0                      0.0                   0.0   \n",
            "\n",
            "   native_country_Taiwan  native_country_Thailand  \\\n",
            "0                    0.0                      0.0   \n",
            "1                    0.0                      0.0   \n",
            "2                    0.0                      0.0   \n",
            "3                    0.0                      0.0   \n",
            "4                    0.0                      0.0   \n",
            "\n",
            "   native_country_Trinadad&Tobago  native_country_United-States  \\\n",
            "0                             0.0                           1.0   \n",
            "1                             0.0                           1.0   \n",
            "2                             0.0                           1.0   \n",
            "3                             0.0                           1.0   \n",
            "4                             0.0                           0.0   \n",
            "\n",
            "   native_country_Vietnam  native_country_Yugoslavia  \n",
            "0                     0.0                        0.0  \n",
            "1                     0.0                        0.0  \n",
            "2                     0.0                        0.0  \n",
            "3                     0.0                        0.0  \n",
            "4                     0.0                        0.0  \n",
            "\n",
            "[5 rows x 108 columns]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are now ready to be fed into the imputation algorithm, which involves three steps. First, we specify the dimensions, input corruption proportion, and other hyperparameters of the MIDAS neural network. Second, we build a MIDAS model based on the data. The vector of one-hot-encoded column names should be passed to the softmax_columns argument, as MIDAS employs a softmax final-layer activation function for categorical variables. Third, we train the model on the data, setting the number of training epochs as 20 in this example:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "imputer = md.Midas(layer_structure = [256,256], vae_layer = False, seed = 89, input_drop = 0.75)\n",
        "imputer.build_model(data_in, softmax_columns = cat_cols_list)\n",
        "imputer.train_model(training_epochs = 20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size index: [7, 8, 7, 6, 5, 2, 2, 16, 14, 41]\n",
            "\n",
            "Computation graph constructed\n",
            "\n",
            "Model initialised\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-21 20:07:10.734701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-21 20:07:10.739202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2021-09-21 20:07:10.739670: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-09-21 20:07:10.740138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 , loss: 131060.12472738164\n",
            "Epoch: 1 , loss: 94869.06297356242\n",
            "Epoch: 2 , loss: 90830.15935247378\n",
            "Epoch: 3 , loss: 88528.95353520745\n",
            "Epoch: 4 , loss: 85461.10624308855\n",
            "Epoch: 5 , loss: 80486.11211142284\n",
            "Epoch: 6 , loss: 76536.06388932974\n",
            "Epoch: 7 , loss: 75540.07280830193\n",
            "Epoch: 8 , loss: 74316.37026309592\n",
            "Epoch: 9 , loss: 73984.68447112037\n",
            "Epoch: 10 , loss: 73999.93967902707\n",
            "Epoch: 11 , loss: 74538.63024502376\n",
            "Epoch: 12 , loss: 73596.38242213098\n",
            "Epoch: 13 , loss: 73786.58791174332\n",
            "Epoch: 14 , loss: 72981.07277246477\n",
            "Epoch: 15 , loss: 73847.48175952757\n",
            "Epoch: 16 , loss: 72961.70744273734\n",
            "Epoch: 17 , loss: 74021.42337696081\n",
            "Epoch: 18 , loss: 73330.54337767755\n",
            "Epoch: 19 , loss: 73336.20200380898\n",
            "Training complete. Saving file...\n",
            "Model saved in file: tmp/MIDAS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MIDASpy.midas_base.Midas at 0x7f9345a3d8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once training is complete, we can generate any number of imputed datasets (M) using the `generate_samples` function (here we set M as 10). Users can then either write these imputations to separate .CSV files or work with them directly in Python:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "imputations = imputer.generate_samples(m=10).output_list \n",
        "\n",
        "# for i in imputations:\n",
        "#    file_out = \"midas_imp_\" + str(n) + \".csv\"\n",
        "#    i.to_csv(file_out, index=False)\n",
        "#    n += 1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from tmp/MIDAS\n",
            "Model restored.\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, using the list of generated imputations, we can estimate M separate regression models and combine the parameter and variance estimates (see Rubin 1987) using **MIDASpy's** `combine` function:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "model = md.combine(y_var = \"capital_gain\", \n",
        "                   X_vars = [\"education_num\",\"age\"],\n",
        "                   df_list = imputations)\n",
        "\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/tsr/.local/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  x = pd.concat(x[::order], 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>estimate</th>\n",
              "      <th>std.error</th>\n",
              "      <th>statistic</th>\n",
              "      <th>df</th>\n",
              "      <th>p.value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>const</td>\n",
              "      <td>-845.602953</td>\n",
              "      <td>131.761974</td>\n",
              "      <td>-6.417655</td>\n",
              "      <td>79.268249</td>\n",
              "      <td>9.372076e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>education_num</td>\n",
              "      <td>57.687455</td>\n",
              "      <td>8.798527</td>\n",
              "      <td>6.556490</td>\n",
              "      <td>26.862490</td>\n",
              "      <td>5.076031e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>age</td>\n",
              "      <td>33.277681</td>\n",
              "      <td>2.480652</td>\n",
              "      <td>13.414893</td>\n",
              "      <td>373.918334</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            term    estimate   std.error  statistic          df       p.value\n",
              "0          const -845.602953  131.761974  -6.417655   79.268249  9.372076e-09\n",
              "1  education_num   57.687455    8.798527   6.556490   26.862490  5.076031e-07\n",
              "2            age   33.277681    2.480652  13.414893  373.918334  0.000000e+00"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling one-hot encoded categories post-imputation\n",
        "\n",
        "To impute categorical data, we one-hot encode the variable and then impute the probability of each class for each observation. For example, if we look at the one-hot encoded `workclass` variable in the imputed data, we see that it is represented by 8 columns, one for each label in the data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "workclasses = [x for x in imputations[0].columns if \"workclass\" in x]\n",
        "imputations[0][workclasses].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass_Federal-gov</th>\n",
              "      <th>workclass_Local-gov</th>\n",
              "      <th>workclass_Never-worked</th>\n",
              "      <th>workclass_Private</th>\n",
              "      <th>workclass_Self-emp-inc</th>\n",
              "      <th>workclass_Self-emp-not-inc</th>\n",
              "      <th>workclass_State-gov</th>\n",
              "      <th>workclass_Without-pay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
              "0                    0.0                  0.0                     0.0   \n",
              "1                    0.0                  0.0                     0.0   \n",
              "2                    0.0                  0.0                     0.0   \n",
              "3                    0.0                  0.0                     0.0   \n",
              "4                    0.0                  0.0                     0.0   \n",
              "\n",
              "   workclass_Private  workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
              "0                0.0                     0.0                         0.0   \n",
              "1                0.0                     0.0                         1.0   \n",
              "2                1.0                     0.0                         0.0   \n",
              "3                1.0                     0.0                         0.0   \n",
              "4                1.0                     0.0                         0.0   \n",
              "\n",
              "   workclass_State-gov  workclass_Without-pay  \n",
              "0                  1.0                    0.0  \n",
              "1                  0.0                    0.0  \n",
              "2                  0.0                    0.0  \n",
              "3                  0.0                    0.0  \n",
              "4                  0.0                    0.0  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, if we want to use the categorical version then we usually want to transform these probabilities back into a vector of labels. The simplest approach is to select the category with the highest probability for each observation. Fortunately, having used `md.conv()` to one-hot encode these variables earlier, we can use the resulting `cat_cols_list` object to do just that. The following code collapses all encoded columns back into single categorical columns:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "flat_cats = [cat for variable in cat_cols_list for cat in variable]\n",
        "\n",
        "for i in range(len(imputations)):\n",
        "    tmp_cat = [imputations[i][x].idxmax(axis=1) for x in cat_cols_list]\n",
        "    cat_df = pd.DataFrame({categorical[i]:tmp_cat[i] for i in range(len(categorical))})\n",
        "    imputations[i] = pd.concat([imputations[i], cat_df], axis = 1).drop(flat_cats, axis = 1)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we now inspect the imputations we can see that our data is back to its original shape. Inspecting the `workclass` column, we see that the categories correspond to the one-hot encoded values identified earlier:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "print(imputations[0].columns)\n",
        "\n",
        "imputations[0]['workclass'].head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'age', 'fnlwgt', 'education_num', 'capital_gain',\n",
            "       'capital_loss', 'hours_per_week', 'workclass', 'marital_status',\n",
            "       'relationship', 'race', 'class_labels', 'sex', 'education',\n",
            "       'occupation', 'native_country'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           workclass_State-gov\n",
              "1    workclass_Self-emp-not-inc\n",
              "2             workclass_Private\n",
              "3             workclass_Private\n",
              "4             workclass_Private\n",
              "Name: workclass, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('midas': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    },
    "interpreter": {
      "hash": "88f65ce5382ce20a2dfcb3047ae19453970fdb3147747ad8e6ead051daaa71e6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}