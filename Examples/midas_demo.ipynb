{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MIDASpy demonstration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides a brief demonstration of **MIDASpy**'s core functionalities. We show how to use the package to impute missing values in the [Adult census dataset](https://github.com/MIDASverse/MIDASpy/blob/master/Examples/adult_data.csv) (which is commonly used for benchmarking machine learning tasks).\n",
        "\n",
        "Users of **MIDASpy** must have **TensorFlow** installed as a **pip** package in their Python environment. **MIDASpy** is compatible with both **TensorFlow** 1.X and **TensorFlow** >= 2.2 versions.\n",
        "\n\nOnce these packages are installed, users can import the dependencies and load the data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import MIDASpy as md\n",
        "\n",
        "data_0 = pd.read_csv('adult_data.csv')\n",
        "data_0.columns.str.strip()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'age', 'workclass', 'fnlwgt', 'education',\n",
              "       'education_num', 'marital_status', 'occupation', 'relationship', 'race',\n",
              "       'sex', 'capital_gain', 'capital_loss', 'hours_per_week',\n",
              "       'native_country', 'class_labels'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the Adult dataset has very little missingness, we randomly set 5,000 observed values as missing in each column:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(441)\n",
        "\n",
        "def spike_in_generation(data):\n",
        "    spike_in = pd.DataFrame(np.zeros_like(data), columns= data.columns)\n",
        "    for column in data.columns:\n",
        "        subset = np.random.choice(data[column].index[data[column].notnull()], 5000, replace= False)\n",
        "        spike_in.loc[subset, column] = 1\n",
        "    return spike_in\n",
        "\n",
        "spike_in = spike_in_generation(data_0)\n",
        "original_value = data_0.loc[4, 'hours_per_week']\n",
        "data_0[spike_in == 1] = np.nan"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we list categorical variables in a vector and one-hot encode them using **MIDASpy**'s inbuilt preprocessing function `cat_conv`, which returns both the encoded data and a nested list of categorical column names we can pass to the imputation algorithm. To construct the final, pre-processed data we append the one-hot encoded categorical data to the non-cateogrical data, and replace null values with `np.nan` values:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = ['workclass','marital_status','relationship','race','class_labels','sex','education','occupation','native_country']\n",
        "data_cat, cat_cols_list = md.cat_conv(data_0[categorical])\n",
        "\n",
        "data_0.drop(categorical, axis = 1, inplace = True)\n",
        "constructor_list = [data_0]\n",
        "constructor_list.append(data_cat)\n",
        "data_in = pd.concat(constructor_list, axis=1)\n",
        "\n",
        "na_loc = data_in.isnull()\n",
        "data_in[na_loc] = np.nan"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the results:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_in.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0   age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
            "0         0.0  39.0   77516.0           13.0        2174.0           0.0   \n",
            "1         1.0  50.0   83311.0           13.0           0.0           0.0   \n",
            "2         2.0  38.0  215646.0            9.0           0.0           0.0   \n",
            "3         3.0  53.0  234721.0            NaN           0.0           0.0   \n",
            "4         4.0  28.0       NaN           13.0           0.0           NaN   \n",
            "\n",
            "   hours_per_week  workclass_Federal-gov  workclass_Local-gov  \\\n",
            "0            40.0                    0.0                  0.0   \n",
            "1            13.0                    0.0                  0.0   \n",
            "2            40.0                    0.0                  0.0   \n",
            "3            40.0                    0.0                  0.0   \n",
            "4             NaN                    0.0                  0.0   \n",
            "\n",
            "   workclass_Never-worked  ...  native_country_Portugal  \\\n",
            "0                     0.0  ...                      0.0   \n",
            "1                     0.0  ...                      0.0   \n",
            "2                     0.0  ...                      0.0   \n",
            "3                     0.0  ...                      0.0   \n",
            "4                     0.0  ...                      0.0   \n",
            "\n",
            "   native_country_Puerto-Rico  native_country_Scotland  native_country_South  \\\n",
            "0                         0.0                      0.0                   0.0   \n",
            "1                         0.0                      0.0                   0.0   \n",
            "2                         0.0                      0.0                   0.0   \n",
            "3                         0.0                      0.0                   0.0   \n",
            "4                         0.0                      0.0                   0.0   \n",
            "\n",
            "   native_country_Taiwan  native_country_Thailand  \\\n",
            "0                    0.0                      0.0   \n",
            "1                    0.0                      0.0   \n",
            "2                    0.0                      0.0   \n",
            "3                    0.0                      0.0   \n",
            "4                    0.0                      0.0   \n",
            "\n",
            "   native_country_Trinadad&Tobago  native_country_United-States  \\\n",
            "0                             0.0                           1.0   \n",
            "1                             0.0                           1.0   \n",
            "2                             0.0                           1.0   \n",
            "3                             0.0                           1.0   \n",
            "4                             0.0                           0.0   \n",
            "\n",
            "   native_country_Vietnam  native_country_Yugoslavia  \n",
            "0                     0.0                        0.0  \n",
            "1                     0.0                        0.0  \n",
            "2                     0.0                        0.0  \n",
            "3                     0.0                        0.0  \n",
            "4                     0.0                        0.0  \n",
            "\n",
            "[5 rows x 108 columns]\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data are now ready to be fed into the imputation algorithm, which involves three steps. First, we specify the dimensions, input corruption proportion, and other hyperparameters of the MIDAS neural network. Second, we build a MIDAS model based on the data. The vector of one-hot-encoded column names should be passed to the softmax_columns argument, as MIDAS employs a softmax final-layer activation function for categorical variables. Third, we train the model on the data, setting the number of training epochs as 20 in this example:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = md.Midas(layer_structure = [256,256], vae_layer = False, seed = 89, input_drop = 0.75)\n",
        "imputer.build_model(data_in, softmax_columns = cat_cols_list)\n",
        "imputer.train_model(training_epochs = 20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size index: [7, 8, 7, 6, 5, 2, 2, 16, 14, 41]\n",
            "\n",
            "Computation graph constructed\n",
            "\n",
            "Model initialised\n",
            "\n",
            "Epoch: 0 , loss: 131055.20626587074\n",
            "Epoch: 1 , loss: 94882.5758455009\n",
            "Epoch: 2 , loss: 90956.90158796997\n",
            "Epoch: 3 , loss: 88764.57763543885\n",
            "Epoch: 4 , loss: 85847.00143988573\n",
            "Epoch: 5 , loss: 80933.15996490518\n",
            "Epoch: 6 , loss: 76754.09316700627\n",
            "Epoch: 7 , loss: 75646.90740190858\n",
            "Epoch: 8 , loss: 74589.6067678469\n",
            "Epoch: 9 , loss: 74155.46380383252\n",
            "Epoch: 10 , loss: 74159.95000204784\n",
            "Epoch: 11 , loss: 74705.84092718402\n",
            "Epoch: 12 , loss: 73753.75950004607\n",
            "Epoch: 13 , loss: 73959.30564486403\n",
            "Epoch: 14 , loss: 73135.93429385444\n",
            "Epoch: 15 , loss: 74014.20066695508\n",
            "Epoch: 16 , loss: 73246.82324794705\n",
            "Epoch: 17 , loss: 74179.63132589798\n",
            "Epoch: 18 , loss: 73412.0879309418\n",
            "Epoch: 19 , loss: 73584.05688892529\n",
            "Training complete. Saving file...\n",
            "Model saved in file: tmp/MIDAS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "<MIDASpy.midas_base.Midas at 0x7fa85ed70c10>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once training is complete, we can generate any number of imputed datasets (M) using the `generate_samples` function (here we set M as 10). Users can then either write these imputations to separate .CSV files or work with them directly in Python:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "imputations = imputer.generate_samples(m=10).output_list \n",
        "\n",
        "# for i in imputations:\n",
        "#    file_out = \"midas_imp_\" + str(n) + \".csv\"\n",
        "#    i.to_csv(file_out, index=False)\n",
        "#    n += 1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from tmp/MIDAS\n",
            "Model restored.\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, using the list of generated imputations, we can estimate M separate regression models and combine the parameter and variance estimates (see Rubin 1987) using **MIDASpy's** `combine` function:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = md.combine(y_var = \"capital_gain\", \n",
        "                   X_vars = [\"education_num\",\"age\"],\n",
        "                   df_list = imputations)\n",
        "\nmodel"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "            term    estimate   std.error  statistic          df       p.value\n",
              "0          const -936.114554  136.800095  -6.842938   75.658615  1.764065e-09\n",
              "1  education_num   67.955119    9.202229   7.384637   26.664184  6.556180e-08\n",
              "2            age   31.339538    2.383158  13.150427  522.516002  0.000000e+00"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>estimate</th>\n",
              "      <th>std.error</th>\n",
              "      <th>statistic</th>\n",
              "      <th>df</th>\n",
              "      <th>p.value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>const</td>\n",
              "      <td>-936.114554</td>\n",
              "      <td>136.800095</td>\n",
              "      <td>-6.842938</td>\n",
              "      <td>75.658615</td>\n",
              "      <td>1.764065e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>education_num</td>\n",
              "      <td>67.955119</td>\n",
              "      <td>9.202229</td>\n",
              "      <td>7.384637</td>\n",
              "      <td>26.664184</td>\n",
              "      <td>6.556180e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>age</td>\n",
              "      <td>31.339538</td>\n",
              "      <td>2.383158</td>\n",
              "      <td>13.150427</td>\n",
              "      <td>522.516002</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling one-hot encoded categories post-imputation\n",
        "\nTo impute categorical data, we one-hot encode the variable and then impute the probability of each class for each observation. For example, if we look at the one-hot encoded `workclass` variable in the imputed data, we see that it is represented by 8 columns, one for each label in the data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "workclasses = [x for x in imputations[0].columns if \"workclass\" in x]\n",
        "imputations[0][workclasses].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": [
              "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
              "0                    0.0                  0.0                     0.0   \n",
              "1                    0.0                  0.0                     0.0   \n",
              "2                    0.0                  0.0                     0.0   \n",
              "3                    0.0                  0.0                     0.0   \n",
              "4                    0.0                  0.0                     0.0   \n",
              "\n",
              "   workclass_Private  workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
              "0                0.0                     0.0                         0.0   \n",
              "1                0.0                     0.0                         1.0   \n",
              "2                1.0                     0.0                         0.0   \n",
              "3                1.0                     0.0                         0.0   \n",
              "4                1.0                     0.0                         0.0   \n",
              "\n",
              "   workclass_State-gov  workclass_Without-pay  \n",
              "0                  1.0                    0.0  \n",
              "1                  0.0                    0.0  \n",
              "2                  0.0                    0.0  \n",
              "3                  0.0                    0.0  \n",
              "4                  0.0                    0.0  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass_Federal-gov</th>\n",
              "      <th>workclass_Local-gov</th>\n",
              "      <th>workclass_Never-worked</th>\n",
              "      <th>workclass_Private</th>\n",
              "      <th>workclass_Self-emp-inc</th>\n",
              "      <th>workclass_Self-emp-not-inc</th>\n",
              "      <th>workclass_State-gov</th>\n",
              "      <th>workclass_Without-pay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, if we want to use the categorical version then we usually want to transform these probabilities back into a vector of labels. The simplest approach is to select the category with the highest probability for each observation. Fortunately, having used `md.conv()` to one-hot encode these variables earlier, we can use the resulting `cat_cols_list` object to do just that. The following code collapses all encoded columns back into single categorical columns:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "flat_cats = [cat for variable in cat_cols_list for cat in variable]\n",
        "\n",
        "for i in range(len(imputations)):\n",
        "    tmp_cat = [imputations[i][x].idxmax(axis=1) for x in cat_cols_list]\n",
        "    cat_df = pd.DataFrame({categorical[i]:tmp_cat[i] for i in range(len(categorical))})\n",
        "    imputations[i] = pd.concat([imputations[i], cat_df], axis = 1).drop(flat_cats, axis = 1)\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we now inspect the imputations we can see that our data is back to its original shape. Inspecting the `workclass` column, we see that the categories correspond to the one-hot encoded values identified earlier:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(imputations[0].columns)\n",
        "\nimputations[0]['workclass'].head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'age', 'fnlwgt', 'education_num', 'capital_gain',\n",
            "       'capital_loss', 'hours_per_week', 'workclass', 'marital_status',\n",
            "       'relationship', 'race', 'class_labels', 'sex', 'education',\n",
            "       'occupation', 'native_country'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": [
              "0           workclass_State-gov\n",
              "1    workclass_Self-emp-not-inc\n",
              "2             workclass_Private\n",
              "3             workclass_Private\n",
              "4             workclass_Private\n",
              "Name: workclass, dtype: object"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    },
    "interpreter": {
      "hash": "88f65ce5382ce20a2dfcb3047ae19453970fdb3147747ad8e6ead051daaa71e6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}